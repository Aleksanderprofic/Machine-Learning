{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of natural_language_processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleksanderprofic/Machine-Learning/blob/master/NaturalLanguageProcessing/SentimentAnalysis/restaurant_reviews_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwK5-9FIB-lu"
      },
      "source": [
        "# Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1kiO9kACE6s"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QG7sxmoCIvN"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTfaCIzdCLPA"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPWmb6mLvHYH"
      },
      "source": [
        "quoting=3 - ignore quotes in text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ujp-85bgugWs",
        "outputId": "6a1df758-38d2-47a1-c659-ddd96b343d5e"
      },
      "source": [
        "dataset = pd.read_csv('Restaurant_Reviews.tsv', sep='\\t', quoting=3)\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Liked\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qekztq71CixT"
      },
      "source": [
        "## Cleaning the texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YozKVqhEuycg",
        "outputId": "c8cd8702-a5ff-4ab5-ab53-0c8881f57caa"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "corpus = []\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "all_stopwords = stopwords.words('english')\n",
        "all_stopwords.remove('not')\n",
        "all_stopwords.remove(\"isn't\")\n",
        "\n",
        "for i, row in dataset.iterrows():\n",
        "    review = re.sub('[^a-zA-Z ]', ' ', row[0])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = ' '.join([stemmer.stem(word) for word in review if word not in set(all_stopwords)])\n",
        "    corpus.append(review)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF3GV_so1Npj",
        "outputId": "c00e3b01-dbc8-4bb5-c478-3c9d5ab7bca7"
      },
      "source": [
        "print(corpus[:5])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['wow love place', 'crust not good', 'not tasti textur nasti', 'stop late may bank holiday rick steve recommend love', 'select menu great price']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLqmAkANCp1-"
      },
      "source": [
        "## Creating the Bag of Words model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjkO77uH3c6G"
      },
      "source": [
        "We include only most frequently used words. There are 1566 words, but we take only 1500"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnLbC0RUuy5C"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(max_features=1500)\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH_VjgPzC2cd"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKlg1g1FuzWt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkIq23vEDIPt"
      },
      "source": [
        "## Training and predicting the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo1jOojCy0t2"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdlCRUW7uzx9",
        "outputId": "ba2138c3-ab09-46ab-bb50-975f59eecb87"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "nb = GaussianNB()\n",
        "accuracies = cross_val_score(estimator=nb, X=X_train, y=y_train, scoring='accuracy', cv=10, n_jobs=-1)\n",
        "print('Mean accuracy: {:.2f}%'.format(accuracies.mean() * 100))\n",
        "print('Standard deviation: {:.2f}%'.format(accuracies.std() * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy: 67.25%\n",
            "Standard deviation: 5.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6qqq4fNy33N"
      },
      "source": [
        "#### Predicting the Test set results and making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RD7GBgBu0DJ",
        "outputId": "0e1667ce-666c-4117-a5c5-3304e1e50339"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score\n",
        "\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred = nb.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f'Confusion matrix: \\n{cm}')\n",
        "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred) * 100))\n",
        "print('Recall: {:.2f}%'.format(recall_score(y_test, y_pred) * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1_score(y_test, y_pred) * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix: \n",
            "[[55 42]\n",
            " [12 91]]\n",
            "Accuracy: 73.00%\n",
            "Recall: 88.35%\n",
            "F1 score: 77.12%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1mDvX-7zkAt"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZDIpqNJzkAu",
        "outputId": "03780dba-90e3-4303-e62f-a114cd052d5a"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = [{'C': [0.1, 0.25, 0.5, 0.75, 1.0], 'max_iter': [100, 200, 300], 'penalty': ['None', 'l2']}]\n",
        "\n",
        "grid_search = GridSearchCV(estimator=LogisticRegression(), param_grid=parameters, scoring='accuracy', n_jobs=-1, cv=10)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print('Best accuracy: {:.2f}%'.format(grid_search.best_score_ * 100))\n",
        "print('Standard deviation: {:.2f}%'.format(grid_search.cv_results_['std_test_score'][grid_search.best_index_] * 100))\n",
        "print(f'Best params: {grid_search.best_params_}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best accuracy: 80.50%\n",
            "Standard deviation: 4.30%\n",
            "Best params: {'C': 1.0, 'max_iter': 100, 'penalty': 'l2'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zie_OTpW0NY3",
        "outputId": "0d2f0746-ee0a-4b70-eecd-6ba046f2b033"
      },
      "source": [
        "classifier = LogisticRegression(C=1.0, max_iter=100, penalty='l2')\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYTXzo1NzkAw"
      },
      "source": [
        "#### Predicting the Test set results and making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHykhWBwzkAw",
        "outputId": "da98f738-050e-4ba8-82e3-7f6ccaa040b7"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score\n",
        "\n",
        "classifier = LogisticRegression(C=1.0, max_iter=100)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f'Confusion matrix: \\n{cm}')\n",
        "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred) * 100))\n",
        "print('Recall: {:.2f}%'.format(recall_score(y_test, y_pred) * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1_score(y_test, y_pred) * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix: \n",
            "[[80 17]\n",
            " [28 75]]\n",
            "Accuracy: 77.50%\n",
            "Recall: 72.82%\n",
            "F1 score: 76.92%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36PrwngP4NVc"
      },
      "source": [
        "### K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txFwJFKM4NVc",
        "outputId": "4883bda5-668c-4aad-fa98-5d797bbd16f6"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = [{'n_neighbors': [5, 10, 15, 20, 30, 50]}]\n",
        "\n",
        "grid_search = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=parameters, scoring='accuracy', n_jobs=-1, cv=10)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print('Best accuracy: {:.2f}%'.format(grid_search.best_score_ * 100))\n",
        "print('Standard deviation: {:.2f}%'.format(grid_search.cv_results_['std_test_score'][grid_search.best_index_] * 100))\n",
        "print(f'Best params: {grid_search.best_params_}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best accuracy: 71.00%\n",
            "Standard deviation: 4.02%\n",
            "Best params: {'n_neighbors': 30}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu6p0T494NVd",
        "outputId": "4e324efd-645e-45e0-e44e-9a652e6ab143"
      },
      "source": [
        "knn_classifier = KNeighborsClassifier(n_neighbors=30)\n",
        "knn_classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=30, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yHCwT_E4NVe"
      },
      "source": [
        "#### Predicting the Test set results and making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAr6hnN14NVe",
        "outputId": "a3a812a0-9f72-4eb2-c6a7-fa2d3c150bbc"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score\n",
        "\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f'Confusion matrix: \\n{cm}')\n",
        "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred) * 100))\n",
        "print('Recall: {:.2f}%'.format(recall_score(y_test, y_pred) * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1_score(y_test, y_pred) * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix: \n",
            "[[84 13]\n",
            " [50 53]]\n",
            "Accuracy: 68.50%\n",
            "Recall: 51.46%\n",
            "F1 score: 62.72%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYg0tnKe9F-j"
      },
      "source": [
        "### Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex0Owl869F-j",
        "outputId": "55716dfb-dd63-4bb1-823a-71e98f204e7c"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = [{'criterion': ['gini', 'entropy']}]\n",
        "\n",
        "grid_search = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=parameters, scoring='accuracy', n_jobs=-1, cv=10)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print('Best accuracy: {:.2f}%'.format(grid_search.best_score_ * 100))\n",
        "print('Standard deviation: {:.2f}%'.format(grid_search.cv_results_['std_test_score'][grid_search.best_index_] * 100))\n",
        "print(f'Best params: {grid_search.best_params_}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best accuracy: 77.38%\n",
            "Standard deviation: 3.37%\n",
            "Best params: {'criterion': 'entropy'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49bSkY_M9F-k",
        "outputId": "5b8747bd-4379-4b9d-a614-7b91fafe1910"
      },
      "source": [
        "tree_classifier = DecisionTreeClassifier(criterion='entropy')\n",
        "tree_classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwChVPem9F-k"
      },
      "source": [
        "#### Predicting the Test set results and making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUUHI--s9F-k",
        "outputId": "d53b58a3-7145-4cb7-ee6d-938effb30e3e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score\n",
        "\n",
        "y_pred = tree_classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f'Confusion matrix: \\n{cm}')\n",
        "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred) * 100))\n",
        "print('Recall: {:.2f}%'.format(recall_score(y_test, y_pred) * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1_score(y_test, y_pred) * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix: \n",
            "[[81 16]\n",
            " [37 66]]\n",
            "Accuracy: 73.50%\n",
            "Recall: 64.08%\n",
            "F1 score: 71.35%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh3PQy_j9iRB"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfApA2y_9iRC",
        "outputId": "d0f3aac4-c61f-49d8-975b-cd1e516a89d5"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = [{'criterion': ['gini', 'entropy'], 'n_estimators': [10, 20, 30, 50, 70, 100, 150]}]\n",
        "\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=parameters, scoring='accuracy', n_jobs=-1, cv=10)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print('Best accuracy: {:.2f}%'.format(grid_search.best_score_ * 100))\n",
        "print('Standard deviation: {:.2f}%'.format(grid_search.cv_results_['std_test_score'][grid_search.best_index_] * 100))\n",
        "print(f'Best params: {grid_search.best_params_}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best accuracy: 79.25%\n",
            "Standard deviation: 3.36%\n",
            "Best params: {'criterion': 'entropy', 'n_estimators': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns9eT3jA9iRC",
        "outputId": "f32c185b-a644-4504-d370-f16d63360db2"
      },
      "source": [
        "rf_classifier = RandomForestClassifier(criterion='entropy', n_estimators=100)\n",
        "rf_classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrTcf7MnEYOp"
      },
      "source": [
        "#### Predicting the Test set results and making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz7xUcBj9iRC",
        "outputId": "213d5245-0f5e-466f-d36f-d2e98968246f"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score\n",
        "\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f'Confusion matrix: \\n{cm}')\n",
        "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred) * 100))\n",
        "print('Recall: {:.2f}%'.format(recall_score(y_test, y_pred) * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1_score(y_test, y_pred) * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix: \n",
            "[[90  7]\n",
            " [38 65]]\n",
            "Accuracy: 77.50%\n",
            "Recall: 63.11%\n",
            "F1 score: 74.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGzt-abR49O6"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JAXT5o449O7",
        "outputId": "3d7869e3-1c71-44cf-c38e-127800620594"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = [{'C': [0.25, 0.5, 0.75, 1.0], 'gamma': ['scale', 0.1, 0.3, 0.5, 0.7, 0.9], 'kernel': ['rbf']},\n",
        "              {'C': [0.25, 0.5, 0.75, 1.0], 'kernel': ['linear']}]\n",
        "\n",
        "grid_search = GridSearchCV(estimator=SVC(), param_grid=parameters, scoring='accuracy', cv=10)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print('Best accuracy: {:.2f}%'.format(grid_search.best_score_ * 100))\n",
        "print('Standard deviation: {:.2f}%'.format(grid_search.cv_results_['std_test_score'][grid_search.best_index_] * 100))\n",
        "print(f'Best params: {grid_search.best_params_}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best accuracy: 80.00%\n",
            "Standard deviation: 4.81%\n",
            "Best params: {'C': 0.5, 'kernel': 'linear'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CEH9gZ05sHL",
        "outputId": "e24493f2-c7d5-4830-e120-16825eb9bf28"
      },
      "source": [
        "svc = SVC(C=0.5, kernel='linear')\n",
        "svc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djRELdim5sHM"
      },
      "source": [
        "#### Predicting the Test set results and making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKVye_qg5sHM",
        "outputId": "f3002fe6-d295-4ae6-aa20-716ed713ddc2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score\n",
        "\n",
        "y_pred = svc.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f'Confusion matrix: \\n{cm}')\n",
        "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred) * 100))\n",
        "print('Recall: {:.2f}%'.format(recall_score(y_test, y_pred) * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1_score(y_test, y_pred) * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix: \n",
            "[[80 17]\n",
            " [32 71]]\n",
            "Accuracy: 75.50%\n",
            "Recall: 68.93%\n",
            "F1 score: 74.35%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dZ_bEDxENSU"
      },
      "source": [
        "Naive Bayes and Logistic Regression seem like the best models for this problem."
      ]
    }
  ]
}